words = """Как системы RAG уменьшают количество «галлюцинаций» в приложениях на основе больших языковых моделей
Большие языковые модели (БЯМ) обладают мощным потенциалом, но в реальных продуктах у них есть предсказуемый недостаток: они могут генерировать связные ответы, не соответствующие действительности. Генерация с дополняющим поиском (Retrieval-Augmented Generation, RAG) — один из наиболее практичных способов уменьшить количество таких «галлюцинаций», подкрепляя результаты работы модели внешними, поддающимися проверке источниками. Вместо того чтобы заставлять модель полагаться только на «память» о том, чему она обучалась, RAG превращает ваше приложение в систему поиска + синтеза, которая может ссылаться на использованные источники и воздерживаться от выдачи результатов, если доказательств недостаточно.

Ниже приведено практическое руководство о том, как RAG помогает бороться с «галлюцинациями», что может пойти не так и как создать и оценить конвейер RAG, повышающий уровень доверия.

Что такое «галлюцинация» в производственных приложениях на основе больших языковых моделей
В производственных условиях «галлюцинация» обычно означает, что система выдает утверждение, которое:

не подтверждается предоставленным контекстом, или
представлено как факт без доказательств, или
противоречит имеющимся источникам.
Это важно даже в тех случаях, когда ответы «кажутся разумными». В ботах службы поддержки, внутренних системах помощи на основе знаний, процессах обеспечения соответствия требованиям и аналитических системах необоснованное утверждение может привести к реальным рискам: принятию неверных решений, нарушениям правил и подрыву доверия пользователей.

Почему возникают галлюцинации (основные причины)
Галлюцинации не случайны: они часто отражают модель, которая пытается создать правдоподобную реакцию в условиях ограничений.

Отсутствует контекст / вынужденное угадывание. Когда пользователи спрашивают о политике конфиденциальности, деталях нишевого продукта или внутренних документах, модель может не иметь надежной информации и заполнять пробелы с помощью шаблонов из обучающих данных.
Устаревшие учебные данные. Даже надежные модели могут устареть из-за быстро меняющейся документации, ценообразования, нормативных актов или поведения продукта.
Неоднозначные вопросы. Если запрос недостаточно конкретизирован (“Разрешено ли это?” «Каков предел?»), модель может додумывать детали, которые пользователь не указал.
Избыточная генерация. Большие языковые модели обучены генерировать связный текст, но без ограничений они могут давать категоричные ответы, даже если не уверены.
RAG решает эти проблемы, предоставляя доказательства во время выполнения и подталкивая систему к получению ответов из источников, а не к самостоятельному поиску.

Что такое RAG (обзор архитектуры)
Поиск -расширенная генерация объединяет этап поиска с этапом генерации. Каноническая формулировка была представлена Льюисом и др. (2020), который описывает интеграцию непараметрического поиска с параметрической генерацией для наукоемких задач (https://arxiv.org/abs/2005.11401).

В процессе производства RAG обычно проходит четыре стадии:

Индексирование (подготовьте свои знания)

Разбивайте документы на фрагменты, которые можно извлечь
Создавайте эмбеддинги для семантического поиска
Храните метаданные (источник, дату, уровень доступа, область применения продукта)
Многие команды используют библиотеки векторного поиска, такие как FAISS, для эффективного поиска по сходству (https://faiss.ai/)
Поиск (найдите вероятные доказательства)

Поиск по векторному сходству, поиск по ключевым словам или гибридные подходы
Дополнительная фильтрация по метаданным (например, «кадровая политика», «регион = ЕС»)
Дополнение (создание контекстного окна)

Выберите лучшие отрывки
Удалите дубликаты и упорядочьте их
Вставьте их в запрос в качестве «Контекста» или «Источников»
Генерация (ответ с ограничениями + ссылки на источники)

Поручите языковой модели ответить, используя только указанные источники
Укажите источники ключевых утверждений
Распространенные шаблоны реализации описаны в кулинарной книге OpenAI и руководствах по LangChain RAG (https://cookbook.openai.com/, https://python.langchain.com/docs/tutorials/rag/)
Механизмы, с помощью которых RAG уменьшает количество галлюцинаций
RAG наиболее эффективен в борьбе с фактическими галлюцинациями — утверждениями о мире, политике, продукте или документе. Ниже перечислены основные механизмы.

1) Закрепление пройденного материала
Самый простой механизм — это обоснование: привязка ответа модели к фрагментам, взятым из внешнего корпуса. Вместо того чтобы полагаться на то, что «помнит» модель, система предоставляет текст, который можно процитировать или обобщить.

Льюис и соавторы (2020) рассматривают RAG как сочетание параметрической памяти (весовых коэффициентов модели) с непараметрической памятью (полученными документами), что повышает эффективность выполнения задач, требующих больших знаний, за счет обращения к внешней информации (https://arxiv.org/abs/2005.11401). Проще говоря, модель может перестать гадать и начать читать.

2) Смещение фокуса с «генерации» на «восстановление» (более решаемая проблема)
Без RAG распространенным сценарием сбоя является: модель генерирует. С RAG сценарий сбоя часто выглядит так: система получила неверные данные.

Этот сдвиг полезен с практической точки зрения. Качество поиска можно измерить и улучшить с помощью технических средств — более эффективного разбиения на фрагменты, встраивания, гибридного поиска, фильтров и повторного ранжирования. Кроме того, это упрощает отладку: можно проверить, что именно было найдено и почему.

3) Указание источника (цитирование) и ограниченные подсказки
Для многих реализаций RAG требуется:

«Отвечайте только на основе указанных источников».
«Если в источниках нет ответа, скажите, что вы не знаете».
«Процитируйте использованные отрывки из источников».
Эти ограничения сокращают количество степеней свободы модели и упрощают выявление необоснованных утверждений в тестовых и рабочих журналах. В документации по платформам, направленной на снижение количества «галлюцинаций», также особое внимание уделяется обоснованию и атрибуции, как, например, в обзоре Google Cloud (https://cloud.google.com/vertex-ai/docs/generative-ai/grounding/overview).

Практичный формат вывода, поддерживающий проверку:

Ответ
Ссылки на источники
Примечания / предположения
Открытые вопросы (если доказательств недостаточно)
4) Отказ/воздержание от участия становится более надежным сигналом для извлечения данных
Общее производственное требование: не гадайте. RAG позволяет это сделать с помощью сигналов для извлечения данных:

Если ни один отрывок не соответствует пороговому значению релевантности, система может:
скажите: «В предоставленных источниках недостаточно информации»,
задайте уточняющий вопрос или
переадресуйте запрос человеку.
Этот подход — один из самых эффективных способов борьбы с «галлюцинациями» в корпоративной среде, поскольку он заменяет изобретательность контролируемой неопределенностью.

5) Более быстрое обновление знаний за счет обновления корпуса
Исправление «галлюцинаций» с помощью переобучения или тонкой настройки может быть медленным и неполным. RAG позволяет вносить множество фактических исправлений, обновляя базовый корпус данных (документацию, страницы с описанием политики, часто задаваемые вопросы о продуктах) и переиндексируя его, чтобы при последующем поиске отображались исправленные достоверные источники.

6) Повышение прозрачности и возможности аудита
Системы RAG могут вести журнал регистрации:

запрос пользователя,
найденные отрывки,
окончательный ответ,
использованные цитаты.
Таким образом создается контрольный журнал — «почему модель выдала такой результат?», — который помогает в отладке, соблюдении нормативных требований и итеративном совершенствовании. Такие платформы, как LlamaIndex, делают упор на оценку и анализ поведения при извлечении и синтезе данных (https://docs.llamaindex.ai/).

Инженерные решения, которые еще больше снижают вероятность галлюцинаций
RAG — это не переключатель, который можно просто включить. Лучше всего он работает, когда извлечение и синтез данных организованы целенаправленно.

Переписывание и декомпозиция запросов

Перепишите короткие или двусмысленные запросы так, чтобы их было удобно обрабатывать.
Разбейте сложные вопросы на подзапросы, обработайте каждый из них, а затем объедините результаты.
Гибридное извлечение + повторный ранжирование

Сочетайте поиск по ключевым словам (точные совпадения) с векторным поиском (семантические совпадения).
Используйте рераннер для изменения порядка извлеченных фрагментов, чтобы наиболее релевантные результаты отображались в начале списка. В документации LangChain описаны распространенные методы извлечения и ранжирования (https://python.langchain.com/docs/tutorials/rag/).
Стратегия разбиения на фрагменты и фильтры метаданных

Разбивайте на смысловые блоки (разделы, заголовки), а не на фиксированное количество токенов.
Добавляйте метаданные, такие как тип документа, версия и средства контроля доступа; соответствующим образом фильтруйте поиск, чтобы избежать нерелевантного или несанкционированного контекста.
Бюджетирование и дедупликация в контекстном окне

Удалите почти повторяющиеся фрагменты.
Отдавайте предпочтение меньшим по объему, но более качественным фрагментам, которые напрямую отвечают на вопрос.
Ограничения: «использовать только предоставленные источники»

Четко сформулируйте: «Если этого нет в источниках, скажите, что вам неизвестно».
Требуйте указывать источники для каждого абзаца или утверждения.
Проверка после генерации

Проверьте цитаты: действительно ли приведенные отрывки подтверждают каждое из утверждений?
Добавьте оценку достоверности и обоснованности. LlamaIndex выделяет концепции оценки систем RAG, в том числе подходы, основанные на достоверности и обоснованности (https://docs.llamaindex.ai/).
Как оценить «снижение галлюцинаций» при расстройствах аутистического спектра
Оценка становится более действенной, если отделить проблемы извлечения информации от проблем ее генерации.

Показатели поиска

Recall@k: появляется ли нужный отрывок в первых k результатах поиска?
MRR / nDCG: насколько высоко в поисковой выдаче находится релевантное доказательство?
Основательность / верность

Есть ли подтверждение для каждого предложения с ответом в найденном контексте?
Точны ли цитаты (указывают ли они на подтверждающие текст источники)?
Комплексное выполнение задач

Критерии оценки рецензентами: правильность, полнота, безопасное воздержание от публикации и качество цитирования.
Регрессионное тестирование с помощью логирования и воспроизведения: повторный запуск предыдущих запросов после внесения изменений в индекс или промпт для выявления регрессий.
Такое разделение позволяет избежать ложной уверенности: если обоснованность низкая, но способность к воспроизведению высокая, исправьте генератор/подсказку; если способность к воспроизведению низкая, никакая подсказка не поможет избежать галлюцинаций.

Когда RAG — неподходящий (или недостаточный) инструмент
RAG в первую очередь направлен на фактическую обоснованность. Он может не решить следующие проблемы:

Ошибки в рассуждениях (неверная логика даже при наличии правильных исходных данных)
Неверное толкование (модель неправильно интерпретирует отрывок)
Чрезмерное обобщение (превращение конкретного правила в универсальное)
RAG также может дать сбой в следующих случаях:

при извлечении данных возвращаются нерелевантные или некачественные фрагменты (мусор на входе — мусор на выходе),
контекстные окна обрезают ключевые доказательства,
корпус данных устарел или не является авторитетным,
отсутствуют средства контроля конфиденциальности и безопасности (при извлечении данных может раскрываться конфиденциальная информация).
В таких случаях может потребоваться более тщательная проверка, улучшенный контроль источников и/или участие человека в процессе принятия решений.

Контрольный список внедрения для команд
Сформируйте авторитетный корпус с разделением на версии и правилами определения достоверных источников.
Создайте индекс с четким разделением на фрагменты и метаданными; используйте надежный векторный поиск (например, FAISS: https://faiss.ai/).
Внедрите гибридный поиск и рассмотрите возможность повторного ранжирования для повышения точности.
Добавьте подсказку «использовать только источники» и возвращайте цитаты.
При низкой достоверности результатов поиска добавляйте функцию воздержания от выдачи результатов.
Записывайте запросы, полученные контексты, результаты и цитаты для контроля.
Оценивайте по отдельности: качество поиска, обоснованность/точность цитирования и общую эффективность.
Заключение
RAG уменьшает количество «галлюцинаций», меняя подход к работе больших языковых моделей с «ответа на основе памяти» на «ответ на основе доказательств». Благодаря извлечению релевантных фрагментов во время выполнения, ограничению генерации этими источниками и отказу от генерации при отсутствии доказательств RAG делает приложения на основе больших языковых моделей более надежными и простыми в отладке. Главное — рассматривать извлечение данных как первостепенный компонент: при высоком качестве извлечения данных и подсказках, требующих обоснованных ответов с цитатами, «галлюцинации» возникают реже и их легче обнаружить."""

print(len(words.split()))